//! meshoptimizer - version 0.20

const std = @import("std");

/// Vertex attribute stream
/// Each element takes size bytes, beginning at data, with stride controlling the spacing between successive elements (stride >= size).
pub const Stream = extern struct {
    data: ?*const anyopaque,
    size: usize,
    stride: usize,
};

/// Generates a vertex remap table from the vertex buffer and an optional index buffer and returns number of unique vertices
/// As a result, all vertices that are binary equivalent map to the same (new) location, with no gaps in the resulting sequence.
/// Resulting remap table maps old vertices to new vertices and can be used in meshopt_remapVertexBuffer/meshopt_remapIndexBuffer.
/// Note that binary equivalence considers all vertex_size bytes, including padding which should be zero-initialized.
///
/// destination must contain enough space for the resulting remap table (vertex_count elements)
/// indices can be NULL if the input is unindexed
pub fn generateVertexRemap(
    destination: []c_uint,
    indices: ?[]const c_uint,
    comptime T: type,
    vertices: []const T,
) usize {
    std.debug.assert(destination.len >= vertices.len);

    return meshopt_generateVertexRemap(
        destination.ptr,
        if (indices) |p| p.ptr else null,
        if (indices) |p| p.len else vertices.len,
        @ptrCast(vertices.ptr),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_generateVertexRemap(destination: [*]c_uint, indices: ?[*]const c_uint, index_count: usize, vertices: *const anyopaque, vertex_count: usize, vertex_size: usize) usize;

/// Generates a vertex remap table from multiple vertex streams and an optional index buffer and returns number of unique vertices
/// As a result, all vertices that are binary equivalent map to the same (new) location, with no gaps in the resulting sequence.
/// Resulting remap table maps old vertices to new vertices and can be used in meshopt_remapVertexBuffer/meshopt_remapIndexBuffer.
/// To remap vertex buffers, you will need to call meshopt_remapVertexBuffer for each vertex stream.
/// Note that binary equivalence considers all size bytes in each stream, including padding which should be zero-initialized.
///
/// destination must contain enough space for the resulting remap table (vertex_count elements)
/// indices can be NULL if the input is unindexed
/// stream_count must be <= 16
pub fn generateVertexRemapMulti(
    destination: []c_uint,
    indices: ?[]const c_uint,
    vertex_count: usize,
    streams: []const Stream,
) usize {
    std.debug.assert(destination.len >= vertex_count);

    return meshopt_generateVertexRemapMulti(
        destination.ptr,
        if (indices) |p| p.ptr else null,
        if (indices) |p| p.len else 0,
        vertex_count,
        streams.ptr,
        streams.len,
    );
}
extern fn meshopt_generateVertexRemapMulti(destination: [*]c_uint, indices: ?[*]const c_uint, index_count: usize, vertex_count: usize, streams: [*]const Stream, stream_count: usize) usize;

/// Generates vertex buffer from the source vertex buffer and remap table generated by meshopt_generateVertexRemap
///
/// destination must contain enough space for the resulting vertex buffer (unique_vertex_count elements, returned by meshopt_generateVertexRemap)
/// vertex_count should be the initial vertex count and not the value returned by meshopt_generateVertexRemap
pub fn remapVertexBuffer(
    comptime T: type,
    destination: []T,
    vertices: []const T,
    remap: []const c_uint,
) void {
    meshopt_remapVertexBuffer(
        destination.ptr,
        @ptrCast(vertices.ptr),
        vertices.len,
        @sizeOf(T),
        remap.ptr,
    );
}
extern fn meshopt_remapVertexBuffer(destination: *anyopaque, vertices: *const anyopaque, vertex_count: usize, vertex_size: usize, remap: [*]const c_uint) void;

/// Generate index buffer from the source index buffer and remap table generated by meshopt_generateVertexRemap
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
/// indices can be NULL if the input is unindexed
pub fn remapIndexBuffer(
    destination: []c_uint,
    indices: ?[]const c_uint,
    remap: []const c_uint,
) void {
    std.debug.assert(destination.len >= remap.len);

    meshopt_remapIndexBuffer(
        destination.ptr,
        if (indices) |p| p.ptr else null,
        if (indices) |p| p.len else remap.len,
        remap.ptr,
    );
}
extern fn meshopt_remapIndexBuffer(destination: [*]c_uint, indices: ?[*]const c_uint, index_count: usize, remap: [*]const c_uint) void;

/// Generate index buffer that can be used for more efficient rendering when only a subset of the vertex attributes is necessary
/// All vertices that are binary equivalent (wrt first vertex_size bytes) map to the first vertex in the original vertex buffer.
/// This makes it possible to use the index buffer for Z pre-pass or shadowmap rendering, while using the original index buffer for regular rendering.
/// Note that binary equivalence considers all vertex_size bytes, including padding which should be zero-initialized.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
pub fn generateShadowIndexBuffer(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    vertex_size: usize,
) void {
    std.debug.assert(destination.len >= indices.len);

    meshopt_generateShadowIndexBuffer(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrCast(vertices.ptr),
        vertices.len,
        vertex_size,
        @sizeOf(T),
    );
}
extern fn meshopt_generateShadowIndexBuffer(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertices: *const anyopaque, vertex_count: usize, vertex_size: usize, vertex_stride: usize) void;

/// Generate index buffer that can be used for more efficient rendering when only a subset of the vertex attributes is necessary
/// All vertices that are binary equivalent (wrt specified streams) map to the first vertex in the original vertex buffer.
/// This makes it possible to use the index buffer for Z pre-pass or shadowmap rendering, while using the original index buffer for regular rendering.
/// Note that binary equivalence considers all size bytes in each stream, including padding which should be zero-initialized.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
/// stream_count must be <= 16
pub fn generateShadowIndexBufferMulti(
    destination: []c_uint,
    indices: []const c_uint,
    vertex_count: usize,
    streams: []const Stream,
) void {
    std.debug.assert(destination.len >= indices.len);

    meshopt_generateShadowIndexBufferMulti(
        destination.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
        streams.ptr,
        streams.len,
    );
}
extern fn meshopt_generateShadowIndexBufferMulti(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_count: usize, streams: [*]const Stream, stream_count: usize) void;

/// Generate index buffer that can be used as a geometry shader input with triangle adjacency topology
/// Each triangle is converted into a 6-vertex patch with the following layout:
/// - 0, 2, 4: original triangle vertices
/// - 1, 3, 5: vertices adjacent to edges 02, 24 and 40
/// The resulting patch can be rendered with geometry shaders using e.g. VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY.
/// This can be used to implement algorithms like silhouette detection/expansion and other forms of GS-driven rendering.
///
/// destination must contain enough space for the resulting index buffer (index_count*2 elements)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
pub fn generateAdjacencyIndexBuffer(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
) void {
    std.debug.assert(destination.len >= indices.len * 2);

    meshopt_generateAdjacencyIndexBuffer(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_generateAdjacencyIndexBuffer(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize) void;

/// Generate index buffer that can be used for PN-AEN tessellation with crack-free displacement
/// Each triangle is converted into a 12-vertex patch with the following layout:
/// - 0, 1, 2: original triangle vertices
/// - 3, 4: opposing edge for edge 0, 1
/// - 5, 6: opposing edge for edge 1, 2
/// - 7, 8: opposing edge for edge 2, 0
/// - 9, 10, 11: dominant vertices for corners 0, 1, 2
/// The resulting patch can be rendered with hardware tessellation using PN-AEN and displacement mapping.
/// See "Tessellation on Any Budget" (John McDonald, GDC 2011) for implementation details.
///
/// destination must contain enough space for the resulting index buffer (index_count*4 elements)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
pub fn generateTessellationIndexBuffer(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
) void {
    std.debug.assert(destination.len >= indices.len * 4);

    meshopt_generateTessellationIndexBuffer(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_generateTessellationIndexBuffer(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize) void;

/// Vertex transform cache optimizer
/// Reorders indices to reduce the number of GPU vertex shader invocations
/// If index buffer contains multiple ranges for multiple draw calls, this functions needs to be called on each range individually.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
pub fn optimizeVertexCache(
    destination: []c_uint,
    indices: []const c_uint,
    vertex_count: usize,
) void {
    meshopt_optimizeVertexCache(
        destination.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
    );
}
extern fn meshopt_optimizeVertexCache(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_count: usize) void;

/// Vertex transform cache optimizer for strip-like caches
/// Produces inferior results to meshopt_optimizeVertexCache from the GPU vertex cache perspective
/// However, the resulting index order is more optimal if the goal is to reduce the triangle strip length or improve compression efficiency
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
pub fn optimizeVertexCacheStrip(
    destination: []c_uint,
    indices: []const c_uint,
    vertex_count: usize,
) void {
    meshopt_optimizeVertexCacheStrip(
        destination.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
    );
}
extern fn meshopt_optimizeVertexCacheStrip(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_count: usize) void;

/// Vertex transform cache optimizer for FIFO caches
/// Reorders indices to reduce the number of GPU vertex shader invocations
/// Generally takes ~3x less time to optimize meshes but produces inferior results compared to meshopt_optimizeVertexCache
/// If index buffer contains multiple ranges for multiple draw calls, this functions needs to be called on each range individually.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
/// cache_size should be less than the actual GPU cache size to avoid cache thrashing
pub fn optimizeVertexCacheFifo(
    destination: []c_uint,
    indices: []const c_uint,
    vertex_count: usize,
    cache_size: c_uint,
) void {
    meshopt_optimizeVertexCacheFifo(
        destination.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
        cache_size,
    );
}
extern fn meshopt_optimizeVertexCacheFifo(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_count: usize, cache_size: c_uint) void;

/// Overdraw optimizer
/// Reorders indices to reduce the number of GPU vertex shader invocations and the pixel overdraw
/// If index buffer contains multiple ranges for multiple draw calls, this functions needs to be called on each range individually.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
/// indices must contain index data that is the result of meshopt_optimizeVertexCache (*not* the original mesh indices!)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// threshold indicates how much the overdraw optimizer can degrade vertex cache efficiency (1.05 = up to 5%) to reduce overdraw more efficiently
pub fn optimizeOverdraw(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    threshold: f32,
) void {
    meshopt_optimizeOverdraw(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        threshold,
    );
}
extern fn meshopt_optimizeOverdraw(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, threshold: f32) void;

/// Vertex fetch cache optimizer
/// Reorders vertices and changes indices to reduce the amount of GPU memory fetches during vertex processing
/// Returns the number of unique vertices, which is the same as input vertex count unless some vertices are unused
/// This functions works for a single vertex stream; for multiple vertex streams, use meshopt_optimizeVertexFetchRemap + meshopt_remapVertexBuffer for each stream.
///
/// destination must contain enough space for the resulting vertex buffer (vertex_count elements)
/// indices is used both as an input and as an output index buffer
pub fn optimizeVertexFetch(
    comptime T: type,
    destination: []T,
    indices: []c_uint,
    vertices: []const T,
) usize {
    return meshopt_optimizeVertexFetch(
        @ptrCast(destination.ptr),
        indices.ptr,
        indices.len,
        @ptrCast(vertices.ptr),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_optimizeVertexFetch(destination: *anyopaque, indices: [*]c_uint, index_count: usize, vertices: *const anyopaque, vertex_count: usize, vertex_size: usize) usize;

/// Vertex fetch cache optimizer
/// Generates vertex remap to reduce the amount of GPU memory fetches during vertex processing
/// Returns the number of unique vertices, which is the same as input vertex count unless some vertices are unused
/// The resulting remap table should be used to reorder vertex/index buffers using meshopt_remapVertexBuffer/meshopt_remapIndexBuffer
///
/// destination must contain enough space for the resulting remap table (vertex_count elements)
pub fn optimizeVertexFetchRemap(
    destination: []c_uint,
    indices: []const c_uint,
    vertex_count: usize,
) usize {
    return meshopt_optimizeVertexFetchRemap(
        destination.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
    );
}
extern fn meshopt_optimizeVertexFetchRemap(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_count: usize) usize;

/// Index buffer encoder
/// Encodes index data into an array of bytes that is generally much smaller (<1.5 bytes/triangle) and compresses better (<1 bytes/triangle) compared to original.
/// Input index buffer must represent a triangle list.
/// Returns encoded data size on success, 0 on error; the only error condition is if buffer doesn't have enough space
/// For maximum efficiency the index buffer being encoded has to be optimized for vertex cache and vertex fetch first.
///
/// buffer must contain enough space for the encoded index buffer (use meshopt_encodeIndexBufferBound to compute worst case size)
pub extern fn meshopt_encodeIndexBuffer(buffer: [*]u8, buffer_size: usize, indices: [*]const c_uint, index_count: usize) usize;
pub extern fn meshopt_encodeIndexBufferBound(index_count: usize, vertex_count: usize) usize;

/// Set index encoder format version
/// version must specify the data format version to encode; valid values are 0 (decodable by all library versions) and 1 (decodable by 0.14+)
pub extern fn meshopt_encodeIndexVersion(version: c_int) void;

/// Index buffer decoder
/// Decodes index data from an array of bytes generated by meshopt_encodeIndexBuffer
/// Returns 0 if decoding was successful, and an error code otherwise
/// The decoder is safe to use for untrusted input, but it may produce garbage data (e.g. out of range indices).
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
pub extern fn meshopt_decodeIndexBuffer(destination: *anyopaque, index_count: usize, index_size: usize, buffer: [*]const u8, buffer_size: usize) c_int;

/// Index sequence encoder
/// Encodes index sequence into an array of bytes that is generally smaller and compresses better compared to original.
/// Input index sequence can represent arbitrary topology; for triangle lists meshopt_encodeIndexBuffer is likely to be better.
/// Returns encoded data size on success, 0 on error; the only error condition is if buffer doesn't have enough space
///
/// buffer must contain enough space for the encoded index sequence (use meshopt_encodeIndexSequenceBound to compute worst case size)
pub extern fn meshopt_encodeIndexSequence(buffer: [*]u8, buffer_size: usize, indices: [*]const c_uint, index_count: usize) usize;
pub extern fn meshopt_encodeIndexSequenceBound(index_count: usize, vertex_count: usize) usize;

/// Index sequence decoder
/// Decodes index data from an array of bytes generated by meshopt_encodeIndexSequence
/// Returns 0 if decoding was successful, and an error code otherwise
/// The decoder is safe to use for untrusted input, but it may produce garbage data (e.g. out of range indices).
///
/// destination must contain enough space for the resulting index sequence (index_count elements)
pub extern fn meshopt_decodeIndexSequence(destination: *anyopaque, index_count: usize, index_size: usize, buffer: [*]const u8, buffer_size: usize) c_int;

/// Vertex buffer encoder
/// Encodes vertex data into an array of bytes that is generally smaller and compresses better compared to original.
/// Returns encoded data size on success, 0 on error; the only error condition is if buffer doesn't have enough space
/// This function works for a single vertex stream; for multiple vertex streams, call meshopt_encodeVertexBuffer for each stream.
/// Note that all vertex_size bytes of each vertex are encoded verbatim, including padding which should be zero-initialized.
///
/// buffer must contain enough space for the encoded vertex buffer (use meshopt_encodeVertexBufferBound to compute worst case size)
pub extern fn meshopt_encodeVertexBuffer(buffer: [*]u8, buffer_size: usize, vertices: *const anyopaque, vertex_count: usize, vertex_size: usize) usize;
pub extern fn meshopt_encodeVertexBufferBound(vertex_count: usize, vertex_size: usize) usize;

/// Set vertex encoder format version
/// version must specify the data format version to encode; valid values are 0 (decodable by all library versions)
pub extern fn meshopt_encodeVertexVersion(version: c_int) void;

/// Vertex buffer decoder
/// Decodes vertex data from an array of bytes generated by meshopt_encodeVertexBuffer
/// Returns 0 if decoding was successful, and an error code otherwise
/// The decoder is safe to use for untrusted input, but it may produce garbage data.
///
/// destination must contain enough space for the resulting vertex buffer (vertex_count * vertex_size bytes)
pub extern fn meshopt_decodeVertexBuffer(destination: *anyopaque, vertex_count: usize, vertex_size: usize, buffer: [*]const u8, buffer_size: usize) c_int;

/// Vertex buffer filters
/// These functions can be used to filter output of meshopt_decodeVertexBuffer in-place.
///
/// meshopt_decodeFilterOct decodes octahedral encoding of a unit vector with K-bit (K <= 16) signed X/Y as an input; Z must store 1.0f.
/// Each component is stored as an 8-bit or 16-bit normalized integer; stride must be equal to 4 or 8. W is preserved as is.
pub extern fn meshopt_decodeFilterOct(buffer: *anyopaque, count: usize, stride: usize) void;

/// Vertex buffer filters
/// These functions can be used to filter output of meshopt_decodeVertexBuffer in-place.
///
/// meshopt_decodeFilterQuat decodes 3-component quaternion encoding with K-bit (4 <= K <= 16) component encoding and a 2-bit component index indicating which component to reconstruct.
/// Each component is stored as an 16-bit integer; stride must be equal to 8.
pub extern fn meshopt_decodeFilterQuat(buffer: *anyopaque, count: usize, stride: usize) void;

/// Vertex buffer filters
/// These functions can be used to filter output of meshopt_decodeVertexBuffer in-place.
///
/// meshopt_decodeFilterExp decodes exponential encoding of floating-point data with 8-bit exponent and 24-bit integer mantissa as 2^E*M.
/// Each 32-bit component is decoded in isolation; stride must be divisible by 4.
pub extern fn meshopt_decodeFilterExp(buffer: *anyopaque, count: usize, stride: usize) void;

pub const EncodeExpMode = enum(c_uint) {
    /// When encoding exponents, use separate values for each component (maximum quality)
    separate = 0,

    /// When encoding exponents, use shared value for all components of each vector (better compression)
    shared_vector = 1,

    /// When encoding exponents, use shared value for each component of all vectors (best compression) */
    shared_component = 2,
};

/// Vertex buffer filter encoders
/// These functions can be used to encode data in a format that meshopt_decodeFilter can decode
///
/// meshopt_encodeFilterOct encodes unit vectors with K-bit (K <= 16) signed X/Y as an output.
/// Each component is stored as an 8-bit or 16-bit normalized integer; stride must be equal to 4 or 8. W is preserved as is.
/// Input data must contain 4 floats for every vector (count*4 total).
pub extern fn meshopt_encodeFilterOct(destination: *anyopaque, count: usize, stride: usize, bits: c_int, data: [*]const f32) void;

/// Vertex buffer filter encoders
/// These functions can be used to encode data in a format that meshopt_decodeFilter can decode
///
/// meshopt_encodeFilterQuat encodes unit quaternions with K-bit (4 <= K <= 16) component encoding.
/// Each component is stored as an 16-bit integer; stride must be equal to 8.
/// Input data must contain 4 floats for every quaternion (count*4 total).
pub extern fn meshopt_encodeFilterQuat(destination: *anyopaque, count: usize, stride: usize, bits: c_int, data: [*]const f32) void;

/// Vertex buffer filter encoders
/// These functions can be used to encode data in a format that meshopt_decodeFilter can decode
///
/// meshopt_encodeFilterExp encodes arbitrary (finite) floating-point data with 8-bit exponent and K-bit integer mantissa (1 <= K <= 24).
/// Exponent can be shared between all components of a given vector as defined by stride or all values of a given component; stride must be divisible by 4.
/// Input data must contain stride/4 floats for every vector (count*stride/4 total).
pub extern fn meshopt_encodeFilterExp(destination: *anyopaque, count: usize, stride: usize, bits: c_int, data: [*]const f32, mode: EncodeExpMode) void;

/// Simplification options
const SimplifyOptions = packed struct(u32) {
    /// Do not move vertices that are located on the topological border (vertices on triangle edges that don't have a paired triangle). Useful for simplifying portions of the larger mesh.
    lock_border: bool = false,

    __padding: u31 = 0,
};

/// Mesh simplifier
/// Reduces the number of triangles in the mesh, attempting to preserve mesh appearance as much as possible
/// The algorithm tries to preserve mesh topology and can stop short of the target goal based on topology constraints or target error.
/// If not all attributes from the input mesh are required, it's recommended to reindex the mesh using meshopt_generateShadowIndexBuffer prior to simplification.
/// Returns the number of indices after simplification, with destination containing new index data
/// The resulting index buffer references vertices from the original vertex buffer.
/// If the original vertex data isn't required, creating a compact vertex buffer using meshopt_optimizeVertexFetch is recommended.
///
/// destination must contain enough space for the target index buffer, worst case is index_count elements (*not* target_index_count)!
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// target_error represents the error relative to mesh extents that can be tolerated, e.g. 0.01 = 1% deformation; value range [0..1]
/// options must be a bitmask composed of meshopt_SimplifyX options; 0 is a safe default
/// result_error can be NULL; when it's not NULL, it will contain the resulting (relative) error after simplification
pub fn simplify(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    target_index_count: usize,
    target_error: f32,
    options: SimplifyOptions,
    result_error: ?*f32,
) usize {
    return meshopt_simplify(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        target_index_count,
        target_error,
        @intCast(@as(u32, @bitCast(options))),
        result_error,
    );
}
extern fn meshopt_simplify(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, target_index_count: usize, target_error: f32, options: c_uint, result_error: ?*f32) usize;

/// Experimental: Mesh simplifier with attribute metric
/// The algorithm ehnahces meshopt_simplify by incorporating attribute values into the error metric used to prioritize simplification order; see meshopt_simplify documentation for details.
/// Note that the number of attributes affects memory requirements and running time; this algorithm requires ~1.5x more memory and time compared to meshopt_simplify when using 4 scalar attributes.
///
/// vertex_attributes should have attribute_count floats for each vertex
/// attribute_weights should have attribute_count floats in total; the weights determine relative priority of attributes between each other and wrt position. The recommended weight range is [1e-3..1e-1], assuming attribute data is in [0..1] range.
/// attribute_count must be <= 16
/// TODO target_error/result_error currently use combined distance+attribute error; this may change in the future
pub fn simplifyWithAttributes(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    comptime attribute_field: []const u8,
    attribute_weights: []const f32,
    target_index_count: usize,
    target_error: f32,
    options: SimplifyOptions,
    result_error: ?*f32,
) usize {
    return meshopt_simplifyWithAttributes(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, attribute_field),
        ),
        @sizeOf(T),
        attribute_weights.ptr,
        attribute_weights.len,
        target_index_count,
        target_error,
        @intCast(@as(u32, @bitCast(options))),
        result_error,
    );
}
extern fn meshopt_simplifyWithAttributes(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, vertex_attributes: [*]const f32, vertex_attributes_stride: usize, attribute_weights: [*]const f32, attribute_count: usize, target_index_count: usize, target_error: f32, options: c_uint, result_error: ?*f32) usize;

/// Experimental: Mesh simplifier (sloppy)
/// Reduces the number of triangles in the mesh, sacrificing mesh appearance for simplification performance
/// The algorithm doesn't preserve mesh topology but can stop short of the target goal based on target error.
/// Returns the number of indices after simplification, with destination containing new index data
/// The resulting index buffer references vertices from the original vertex buffer.
/// If the original vertex data isn't required, creating a compact vertex buffer using meshopt_optimizeVertexFetch is recommended.
///
/// destination must contain enough space for the target index buffer, worst case is index_count elements (*not* target_index_count)!
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// target_error represents the error relative to mesh extents that can be tolerated, e.g. 0.01 = 1% deformation; value range [0..1]
/// result_error can be NULL; when it's not NULL, it will contain the resulting (relative) error after simplification
pub fn simplifySloppy(
    destination: []c_uint,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    target_index_count: usize,
    target_error: f32,
    result_error: ?*f32,
) usize {
    return meshopt_simplifySloppy(
        destination.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        target_index_count,
        target_error,
        result_error,
    );
}
extern fn meshopt_simplifySloppy(destination: [*]c_uint, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, target_index_count: usize, target_error: f32, result_error: ?*f32) usize;

/// Experimental: Point cloud simplifier
/// Reduces the number of points in the cloud to reach the given target
/// Returns the number of points after simplification, with destination containing new index data
/// The resulting index buffer references vertices from the original vertex buffer.
/// If the original vertex data isn't required, creating a compact vertex buffer using meshopt_optimizeVertexFetch is recommended.
///
/// destination must contain enough space for the target index buffer (target_vertex_count elements)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// vertex_colors should can be NULL; when it's not NULL, it should have float3 color in the first 12 bytes of each vertex
pub fn simplifyPoints(
    destination: []c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    comptime color_field: []const u8,
    color_weight: f32,
    target_vertex_count: usize,
) usize {
    return meshopt_simplifyPoints(
        destination.ptr,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, color_field),
        ),
        @sizeOf(T),
        color_weight,
        target_vertex_count,
    );
}
extern fn meshopt_simplifyPoints(destination: [*]c_uint, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, vertex_colors: [*]const f32, vertex_colors_stride: usize, color_weight: f32, target_vertex_count: usize) usize;

/// Returns the error scaling factor used by the simplifier to convert between absolute and relative extents
///
/// Absolute error must be *divided* by the scaling factor before passing it to meshopt_simplify as target_error
/// Relative error returned by meshopt_simplify via result_error must be *multiplied* by the scaling factor to get absolute error.
pub fn simplifyScale(
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
) f32 {
    return meshopt_simplifyScale(
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_simplifyScale(vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize) f32;

/// Mesh stripifier
/// Converts a previously vertex cache optimized triangle list to triangle strip, stitching strips using restart index or degenerate triangles
/// Returns the number of indices in the resulting strip, with destination containing new index data
/// For maximum efficiency the index buffer being converted has to be optimized for vertex cache first.
/// Using restart indices can result in ~10% smaller index buffers, but on some GPUs restart indices may result in decreased performance.
///
/// destination must contain enough space for the target index buffer, worst case can be computed with meshopt_stripifyBound
/// restart_index should be 0xffff or 0xffffffff depending on index size, or 0 to use degenerate triangles
pub extern fn meshopt_stripify(destination: [*c]c_uint, indices: [*c]const c_uint, index_count: usize, vertex_count: usize, restart_index: c_uint) usize;
pub extern fn meshopt_stripifyBound(index_count: usize) usize;

/// Mesh unstripifier
/// Converts a triangle strip to a triangle list
/// Returns the number of indices in the resulting list, with destination containing new index data
///
/// destination must contain enough space for the target index buffer, worst case can be computed with meshopt_unstripifyBound
pub extern fn meshopt_unstripify(destination: [*c]c_uint, indices: [*c]const c_uint, index_count: usize, restart_index: c_uint) usize;
pub extern fn meshopt_unstripifyBound(index_count: usize) usize;

pub const VertexCacheStatistics = extern struct {
    vertices_transformed: c_uint,
    warps_executed: c_uint,
    acmr: f32,
    atvr: f32,
};

/// Vertex transform cache analyzer
/// Returns cache hit statistics using a simplified FIFO model
/// Results may not match actual GPU performance
pub extern fn meshopt_analyzeVertexCache(indices: [*c]const c_uint, index_count: usize, vertex_count: usize, cache_size: c_uint, warp_size: c_uint, primgroup_size: c_uint) VertexCacheStatistics;

pub const OverdrawStatistics = extern struct {
    pixels_covered: c_uint,
    pixels_shaded: c_uint,
    overdraw: f32,
};

/// Overdraw analyzer
/// Returns overdraw statistics using a software rasterizer
/// Results may not match actual GPU performance
///
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
pub extern fn meshopt_analyzeOverdraw(indices: [*c]const c_uint, index_count: usize, vertex_positions: [*c]const f32, vertex_count: usize, vertex_positions_stride: usize) OverdrawStatistics;

pub const VertexFetchStatistics = extern struct {
    bytes_fetched: c_uint,
    overfetch: f32,
};

/// Vertex fetch cache analyzer
/// Returns cache hit statistics using a simplified direct mapped model
/// Results may not match actual GPU performance
pub extern fn meshopt_analyzeVertexFetch(indices: [*c]const c_uint, index_count: usize, vertex_count: usize, vertex_size: usize) VertexFetchStatistics;

pub const Meshlet = extern struct {
    /// offsets within meshlet_vertices arrays with meshlet data
    vertex_offset: c_uint,

    /// offsets within meshlet_triangles arrays with meshlet data
    triangle_offset: c_uint,

    /// number of vertices used in the meshlet; data is stored in consecutive range defined by offset and count
    vertex_count: c_uint,

    /// number of triangles used in the meshlet; data is stored in consecutive range defined by offset and count
    triangle_count: c_uint,
};

/// Meshlet builder
/// Splits the mesh into a set of meshlets where each meshlet has a micro index buffer indexing into meshlet vertices that refer to the original vertex buffer
/// The resulting data can be used to render meshes using NVidia programmable mesh shading pipeline, or in other cluster-based renderers.
/// When using buildMeshlets, vertex positions need to be provided to minimize the size of the resulting clusters.
/// When using buildMeshletsScan, for maximum efficiency the index buffer being converted has to be optimized for vertex cache first.
///
/// meshlets must contain enough space for all meshlets, worst case size can be computed with meshopt_buildMeshletsBound
/// meshlet_vertices must contain enough space for all meshlets, worst case size is equal to max_meshlets * max_vertices
/// meshlet_triangles must contain enough space for all meshlets, worst case size is equal to max_meshlets * max_triangles * 3
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// max_vertices and max_triangles must not exceed implementation limits (max_vertices <= 255 - not 256!, max_triangles <= 512)
/// cone_weight should be set to 0 when cone culling is not used, and a value between 0 and 1 otherwise to balance between cluster size and cone culling efficiency
pub fn buildMeshlets(
    meshlets: []Meshlet,
    meshlet_vertices: []c_uint,
    meshlet_triangles: []u8,
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
    max_vertices: usize,
    max_triangles: usize,
    cone_weight: f32,
) usize {
    std.debug.assert(meshlet_vertices.len >= meshlets.len * max_vertices);
    std.debug.assert(meshlet_triangles.len >= meshlets.len * max_triangles * 3);

    return meshopt_buildMeshlets(
        meshlets.ptr,
        meshlet_vertices.ptr,
        meshlet_triangles.ptr,
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
        max_vertices,
        max_triangles,
        cone_weight,
    );
}
extern fn meshopt_buildMeshlets(meshlets: [*]Meshlet, meshlet_vertices: [*]c_uint, meshlet_triangles: [*]u8, indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize, max_vertices: usize, max_triangles: usize, cone_weight: f32) usize;

pub fn buildMeshletsScan(
    meshlets: []Meshlet,
    meshlet_vertices: []c_uint,
    meshlet_triangles: []u8,
    indices: []const c_uint,
    vertex_count: usize,
    max_vertices: usize,
    max_triangles: usize,
) usize {
    std.debug.assert(meshlet_vertices.len >= meshlets.len * max_vertices);
    std.debug.assert(meshlet_triangles.len >= meshlets.len * max_triangles * 3);

    return meshopt_buildMeshletsScan(
        meshlets.ptr,
        meshlet_vertices.ptr,
        meshlet_triangles.ptr,
        indices.ptr,
        indices.len,
        vertex_count,
        max_vertices,
        max_triangles,
    );
}
extern fn meshopt_buildMeshletsScan(meshlets: [*]Meshlet, meshlet_vertices: [*]c_uint, meshlet_triangles: [*]u8, indices: [*]const c_uint, index_count: usize, vertex_count: usize, max_vertices: usize, max_triangles: usize) usize;

pub fn buildMeshletsBound(index_count: usize, max_vertices: usize, max_triangles: usize) usize {
    return meshopt_buildMeshletsBound(index_count, max_vertices, max_triangles);
}
extern fn meshopt_buildMeshletsBound(index_count: usize, max_vertices: usize, max_triangles: usize) usize;

/// Cluster bounds generator
/// Creates bounding volumes that can be used for frustum, backface and occlusion culling.
/// For backface culling with orthographic projection, use the following formula to reject backfacing clusters:
///   dot(view, cone_axis) >= cone_cutoff
///
/// For perspective projection, you can use the formula that needs cone apex in addition to axis & cutoff:
///   dot(normalize(cone_apex - camera_position), cone_axis) >= cone_cutoff
///
/// Alternatively, you can use the formula that doesn't need cone apex and uses bounding sphere instead:
///   dot(normalize(center - camera_position), cone_axis) >= cone_cutoff + radius / length(center - camera_position)
/// or an equivalent formula that doesn't have a singularity at center = camera_position:
///   dot(center - camera_position, cone_axis) >= cone_cutoff * length(center - camera_position) + radius
///
/// The formula that uses the apex is slightly more accurate but needs the apex; if you are already using bounding sphere
/// to do frustum/occlusion culling, the formula that doesn't use the apex may be preferable (for derivation see
/// Real-Time Rendering 4th Edition, section 19.3).
///
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
/// index_count/3 should be less than or equal to 512 (the function assumes clusters of limited size)
pub const Bounds = extern struct {
    /// bounding sphere center, useful for frustum and occlusion culling
    center: [3]f32,

    /// bounding sphere radius, useful for frustum and occlusion culling
    radius: f32,

    /// normal cone apex, useful for backface culling
    cone_apex: [3]f32,

    /// normal cone axis, useful for backface culling
    cone_axis: [3]f32,

    /// normal cone cutoff, useful for backface culling
    cone_cutoff: f32,

    /// normal cone axis, stored in 8-bit SNORM format; decode using x/127.0
    cone_axis_s8: [3]i8,

    /// normal cone cutoff, stored in 8-bit SNORM format; decode using x/127.0
    cone_cutoff_s8: i8,
};

pub fn computeClusterBounds(
    indices: []const c_uint,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
) Bounds {
    return meshopt_computeClusterBounds(
        indices.ptr,
        indices.len,
        @ptrFromInt(
            @intFromPtr(vertices.ptr) +
                @offsetOf(T, position_field),
        ),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_computeClusterBounds(indices: [*]const c_uint, index_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize) Bounds;

pub fn computeMeshletBounds(
    meshlet_vertices: [*]const c_uint,
    meshlet_triangles: [*]const u8,
    triangle_count: usize,
    comptime T: type,
    vertices: []const T,
    comptime position_field: []const u8,
) Bounds {
    return meshopt_computeMeshletBounds(
        meshlet_vertices,
        meshlet_triangles,
        triangle_count,
        @ptrFromInt(@intFromPtr(vertices.ptr) + @offsetOf(T, position_field)),
        vertices.len,
        @sizeOf(T),
    );
}
extern fn meshopt_computeMeshletBounds(meshlet_vertices: [*]const c_uint, meshlet_triangles: [*]const u8, triangle_count: usize, vertex_positions: [*]const f32, vertex_count: usize, vertex_positions_stride: usize) Bounds;

/// Spatial sorter
/// Generates a remap table that can be used to reorder points for spatial locality.
/// Resulting remap table maps old vertices to new vertices and can be used in meshopt_remapVertexBuffer.
///
/// destination must contain enough space for the resulting remap table (vertex_count elements)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
pub extern fn meshopt_spatialSortRemap(destination: [*c]c_uint, vertex_positions: [*c]const f32, vertex_count: usize, vertex_positions_stride: usize) void;

/// Experimental: Spatial sorter
/// Reorders triangles for spatial locality, and generates a new index buffer. The resulting index buffer can be used with other functions like optimizeVertexCache.
///
/// destination must contain enough space for the resulting index buffer (index_count elements)
/// vertex_positions should have float3 position in the first 12 bytes of each vertex
pub extern fn meshopt_spatialSortTriangles(destination: [*c]c_uint, indices: [*c]const c_uint, index_count: usize, vertex_positions: [*c]const f32, vertex_count: usize, vertex_positions_stride: usize) void;

/// Set allocation callbacks
/// These callbacks will be used instead of the default operator new/operator delete for all temporary allocations in the library.
/// Note that all algorithms only allocate memory for temporary use.
/// allocate/deallocate are always called in a stack-like order - last pointer to be allocated is deallocated first.
pub fn setAllocator(
    allocate: *const fn (usize) callconv(.C) *anyopaque,
    deallocate: *const fn (?*anyopaque) callconv(.C) void,
) void {
    meshopt_setAllocator(allocate, deallocate);
}
extern fn meshopt_setAllocator(allocate: *const fn (usize) callconv(.C) *anyopaque, deallocate: *const fn (?*anyopaque) callconv(.C) void) void;
